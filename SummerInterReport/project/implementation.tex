%\section{Implementation}
%\subsection{Drizy - Vision}
% \paragraph{}As mentioned previously, Drizy Vision has been deployed using Raspberry Pi 3 Model B and Raspberry Pi Camera Module V2. This not only makes a cost effective solution but also speeds up the acquisition of frames from the camera since the camera module connects directly to the GPU through the CSI port thereby saving CPU processing for computer vision algorithms.  Drizy Vision has been prototyped for pedestrian-to-vehicle collision avoidance using HOG+SVM \cite{dalal2005histograms} for pedestrian detection that has been implemented using OpenCV and Python2.
% \paragraph{}The HOG (\textbf{H}istogram of \textbf{O}riented \textbf{G}radients)  person detector uses a sliding detection window, 64 pixels wide by 128 pixels tall, which is moved around the image at a predefined step-size. At each position of the detector window, a HOG descriptor is computed. This descriptor is then shown to the trained SVM (\textbf{S}upport \textbf{V}ector \textbf{M}achine), which classifies it as either a pedestrian or not a pedestrian. Before proceeding to further details of implementation, we briefly describe the algorithm for calculation of HOG descriptor. \newline{}\newline{}
% \textbf{CALCULATION OF HOG DESCRIPTOR}\newline{}\newline{} 
% To compute the HOG descriptor, an 8x8 pixel cells are operated on within the detection window. Within a cell, the gradient vector at each pixel is computed.
% \begin{figure}[hbtp]
%   \centering
% %   \vspace{-0.2in}
%     \includegraphics[scale= 0.4]{project/images/image1.png}
%   \caption{\textbf{An 8x8 cell in a 64x128 detection window}}
% \end{figure}
% \newline{}The 64 gradient vectors, in 8x8 pixel cell, is taken and put into a 9-bin histogram. The Histogram ranges from 0 to 180 degrees, so there are 20 degrees per bin. For each gradient vector, it's contribution to the histogram is given by the magnitude of the vector.
% \begin{figure}[hbtp]
%   \centering
%     \includegraphics[scale= 0.5]{project/images/image2.png}
%   \caption{\textbf{9-bin histogram of gradient vectors for an 8x8 cell}}
% \end{figure}
% \newline{}In the next step, the histograms are normalised. However, rather than normalising each histogram individually, the cells are first grouped into blocks of 2x2 and normalised based on all histograms in the block. This block normalisation is performed by concatenating the histograms of the four cells within the block into a vector with 36 components (4 histograms x 9 bins per histogram) and dividing this vector by its magnitude to normalise it. The effect of the block overlap is that each cell appears multiple times in the final descriptor, but is normalised by a different set of neighbouring cells.
% \begin{figure}[hbtp]
%   \centering
%     \includegraphics[scale= 0.7]{project/images/image3.png}
%   \caption{\textbf{Block Normalisation}}
% \end{figure}
% \newline{}The 64 x 128 pixel detection window is divided into 7 blocks across and 15 blocks vertically, for a total of 105 blocks. Each block contains 4 cells with a 9-bin histogram for each cell, for a total of 36 values per block. This brings the final descriptor size to 7 blocks across x 15 blocks vertically x 4 cells per block x 9-bins per histogram = 3,780 values. These values are fed to a trained SVM classifer for detection of object of interest, here pedestrians.
% \paragraph{}The state of art object detection techniques are based on deep learning algorithms like faster R-CNN\cite{ren2015faster}(\textbf{R}egions with \textbf{C}onvolutional \textbf{N}eural \textbf{N}etworks) and its derivatives like YOLO\cite{redmon2016you}. However, the real challenge involves running them real-time on embedded platforms. Therefore, as an acceptable trade-off of 0.8 and 9 (Figure \ref{fig:eval2}) between precision and frames processed per second, respectively, we chose HOG+SVM based pedestrian detector. It has been found that an FPPI (false positives per image) value of 0.5 is acceptable for such driver assistance systems. Figure \ref{fig:eval2} shows that our HOG+SVM pedestrian detector lies well below this threshold at fairly high recall rates.

% \begin{figure}[hbtp]
%   \centering
%   \includegraphics[width=0.5\linewidth]{project/images/roi.png}
%     \includegraphics[width=0.4\linewidth]{project/images/pedestrian.png}
%   \caption{\textbf{Selecting Region of Interest from the Camera view prevents algorithm from detecting all the pedestrians, hence increasing its speed. (b) Detecting pedestrians in ROI using HOG + Opencv}}
% \end{figure}
% \paragraph{}The sliding window algorithm employed for pedestrian detection using HOG+SVM further requires optimisation for bring the fps count to match real-time. Therefore, we reduce the number of sliding windows by selecting region of interest based on known geometric constraints. We achieve further improvement in fps by increasing the step-size of the detection window from 4 pixels to 8 pixels in both x and y direction with nearly no compromise in accuracy. Thus, the processing time for each frame is reduced by a factor of 7x (from 1.4 fps to 9.8 fps). Next, we use multi-threading to parallelize the capture of recent camera frames and pedestrian detection for multiple frames. With the optimised detection techniques, Drizy - Vision is capable of detecting pedestrians within the range of 20 metres.
% % Prototyped on Raspberry pi 3 for pedestrian to vehicle collision avoidance.
% % OpenCV and Python 
% % Used raspberry pi cam to interface directly using camera bus.
% % HOG detector
% % Why no Deep learning?
% % Mention that the assistance system like this requires high fps, and accuracy can be compensated accordingly.
% % Why HOG
% % How far our system detects pedestrians - mention number of windows scanned and all. 
% % Effect of different parameters on fps and stuff 
% % Novelty talks: Optimisation techniques employed
% % Optimisation for embedded platform : ROI, threading, using camera bus
%\subsection{Drizy - Com}
\paragraph{}Drizy - COM has been prototyped for vehicle-to-vehicle collision avoidance alerts at 2 accident blackspots at IIT Delhi. The driver is required to turn on the Drizy smartphone application and turn on the volume. The app starts gathering GPS values from the satellites and infers its attribute like blackspot number, road number etc. The estimate of a potential collision is made on the cloud using a linear predictive algorithm.
\paragraph{}Each vehicle entering a specific accident blackspot uploads its GPS derived attributes via the app to the cloud. The cloud maintains a hierarchical structure of the vehicles and their attributes, as shown in Figure \ref{fig:database}. These attributes include speed and direction of navigation(away or toward the accident blackspot) besides the vehicle's latitude, longitude and altitude. The speed and direction of navigation are determined by studying the change in GPS coordinates of the vehicle. The cloud server refers the cloud database to predict potential collisions in a blackspot and alerts the vehicles that could be on probable collision trajectory. The alerts are sounded on the smartphone itself.
\paragraph{}Algorithm 1 discusses how the server predicts impending collisions and calculates time for each vehicle to reach the intersection point. If the difference in estimated time of any two vehicles to approach the intersection is less than a threshold set to 5 secs, then the cloud sends an alert to vehicles of interest. The alerts are received on the application itself and preset alert tones are generated.\\

% // insert flowchart here
% 			Capture Electronic Horizon from cloud → Capture GPS values from smartphone app → Pre-processes it for blackspot selection (Edge Computing) → Uploads encrypted values to cloud database → Server generates alerts (if any) → Send alerts to Smartphone Application. 

The algorithm adapts its threshold according to the speed of the vehicle. For example, if the vehicle is travelling too fast, then the threshold is doubled to 10 secs, so that driver has sufficient time to apply brakes. This reduces the frequency of alerts thus avoiding redundant or false alerts.

\begin{algorithm}
    	\caption{Server Code Algorithm}
    	\label{Server-Code}
    	\begin{algorithmic}[1]
    		\Procedure{Server Code Algorithm}{$.$}
        	\State {For each pair of vehicles in Accident Black Spot}
        	\State {Get vehicle's GPS, speed, road number from Cloud}
        	\If {$road1!=road2$}
    			\If {direction of both vehicles is toward intersection}
        			\State{Find the distance of two vehicles from intersection using Haversine formula \cite{robusto1957cosine}.}
        			\State{Predict times t1 and t2 to reach the intersection using linear predictive model}
        			 %\State {Predict time difference to reach the intersection using linear predictive model}
        			\If {$|t1-t2|$ $<$ threshold}
        		        \State{Send collision alert to vehicles.}
        			%\State {Move to the next pair}
        			\EndIf
        		\EndIf
        	\EndIf
        	\EndProcedure
    	\end{algorithmic}
    \end{algorithm}
\paragraph{}We used Google Firebase for real-time cloud database maintenance and AWS EC2 UBUNTU 16.04 free tier instance for cloud computing.

% \subsection{Combining Drizy-Vision and Drizy-Com}
% \paragraph{}Drizy-Vision and Drizy-Com function as individual modules. However, the efficacy of the system lies in combining these modules. Combining these two modules synchronizes the alerts from the two individual modules which are then sounded via the buzzer used in Drizy-Vision.
% \paragraph{}The user interface of DRIZY app is provided with a \textbf{PAIR} button to allow users to combine the two modules. This gives raspberry pi access to wifi-hotspot of the phone. Raspberry pi is then connected to the database from where it can download and sound vehicle-to-vehicle collision alerts. The algorithms for warning generation to avoid pedestrian-to-vehicle collision run in parallel. 
% % Deploying Drizy - Vision or Drizy - Com can reduce fatal accidents to half. For users who use the complete Drizy system can synchronize alerts from both the systems and receive all their alerts in Drizy - Vision itself. The Drizy - Com app comes with a PAIR button which uses the WI-FI hot-spot of the smart-phone to connect with Drizy - Vision.
